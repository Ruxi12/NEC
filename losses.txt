
-- 20 de iteratii optimizer = Adam(learn_rate=0.001)
        num_epochs = 20
        dropout_rate = 0.2  # Starting dropout rate
        batch_size = 1.0  #
Iteration: 0  Losses: {'ner': 32130.497174617765}
Iteration: 1  Losses: {'ner': 26422.33606710411}
Iteration: 2  Losses: {'ner': 23648.060757928444}
Iteration: 3  Losses: {'ner': 21348.72044798884}
Iteration: 4  Losses: {'ner': 19866.1426787204}
Iteration: 5  Losses: {'ner': 18105.601612591734}
Iteration: 6  Losses: {'ner': 16625.222168629625}
Iteration: 7  Losses: {'ner': 15226.257765910943}
Iteration: 8  Losses: {'ner': 14323.369816150647}
Iteration: 9  Losses: {'ner': 13106.585383394055}
Iteration: 10  Losses: {'ner': 11972.72928144918}
Iteration: 11  Losses: {'ner': 10934.097241434583}
Iteration: 12  Losses: {'ner': 9990.992995560302}
Iteration: 13  Losses: {'ner': 8914.479654786937}
Iteration: 14  Losses: {'ner': 8386.51805605448}
Iteration: 15  Losses: {'ner': 7364.79271582385}
Iteration: 16  Losses: {'ner': 6689.049813197348}
Iteration: 17  Losses: {'ner': 5831.4187722949855}
Iteration: 18  Losses: {'ner': 5247.3340155659}
Iteration: 19  Losses: {'ner': 4499.133023862228}
Precision:  0.8058111380145279
Recall:  0.8220328516734593
F1-score:  0.8138411689185059


-- 10 iteratii, am adaugat vreo 30 de texte extra generate cu chat gpt
Iteration: 0  Losses: {'ner': 39700.76822417689}
Iteration: 1  Losses: {'ner': 25502.544942728447}
Iteration: 2  Losses: {'ner': 20647.652405833356}
Iteration: 3  Losses: {'ner': 17778.27398100447}
Iteration: 4  Losses: {'ner': 15481.121648765595}
Iteration: 5  Losses: {'ner': 14038.953011349613}
Iteration: 6  Losses: {'ner': 12248.650858494453}
Iteration: 7  Losses: {'ner': 10845.953258798612}
Iteration: 8  Losses: {'ner': 9800.787674067204}
Iteration: 9  Losses: {'ner': 8892.884621271558}
Precision:  0.8089559503528839
Recall:  0.821044831419044
F1-score:  0.8149555623659209



-- 20 de epoci de antrenare -> loss-ul scade, insa recall, F1 sunt mai mici 

Iteration: 0  Losses: {'ner': 39821.17529298356}
Iteration: 1  Losses: {'ner': 25257.3296721348}
Iteration: 2  Losses: {'ner': 20778.369161981587}
Iteration: 3  Losses: {'ner': 17860.386915293366}
Iteration: 4  Losses: {'ner': 15538.547767683991}
Iteration: 5  Losses: {'ner': 13747.331818669423}
Iteration: 6  Losses: {'ner': 12108.499821980575}
Iteration: 7  Losses: {'ner': 10886.137104333455}
Iteration: 8  Losses: {'ner': 9547.009949009833}
Iteration: 9  Losses: {'ner': 8868.333231482182}
Iteration: 10  Losses: {'ner': 8130.653817959614}
Iteration: 11  Losses: {'ner': 7407.418789222871}
Iteration: 12  Losses: {'ner': 7050.551252896329}
Iteration: 13  Losses: {'ner': 6670.532749806565}
Iteration: 14  Losses: {'ner': 6075.476736302982}
Iteration: 15  Losses: {'ner': 5582.398344838041}
Iteration: 16  Losses: {'ner': 5288.01906713974}
Iteration: 17  Losses: {'ner': 5000.021254771354}
Iteration: 18  Losses: {'ner': 4849.0924259605445}
Iteration: 19  Losses: {'ner': 4487.990819142679}
Precision:  0.8023566569484937
Recall:  0.8157342225515624
F1-score:  0.8089901402412886



-- am adaugat partea de scor 

Iteration: 0  Losses: {'ner': 39013.6157016868}
Iteration: 1  Losses: {'ner': 24867.1017562274}
Iteration: 2  Losses: {'ner': 20547.603219295874}
Iteration: 3  Losses: {'ner': 17635.69722751665}
Iteration: 4  Losses: {'ner': 15062.28127155799}
Iteration: 5  Losses: {'ner': 13388.176244331155}
Iteration: 6  Losses: {'ner': 11890.789665508148}
Iteration: 7  Losses: {'ner': 10541.517491089444}
Iteration: 8  Losses: {'ner': 9559.91523751775}
Iteration: 9  Losses: {'ner': 8651.50327517148}

Precision:  0.8039429124334785
Recall:  0.8209213288872422
F1-score:  0.8123434158264589




Iteration: 0  Losses: {'ner': 40281.09729158353}
Iteration: 1  Losses: {'ner': 25050.549921328176}
Iteration: 2  Losses: {'ner': 20759.417950281706}
Iteration: 3  Losses: {'ner': 17437.52418812582}
Iteration: 4  Losses: {'ner': 14988.077912482693}
Iteration: 5  Losses: {'ner': 13196.931388790168}
Iteration: 6  Losses: {'ner': 11909.342853853024}
Iteration: 7  Losses: {'ner': 10597.919986218549}
Iteration: 8  Losses: {'ner': 9657.04764285032}
Iteration: 9  Losses: {'ner': 8632.717328139952}
you are a bot that receives a raw text in Romanian language and returns entity information in a structured manner. For example for this text:
'Început de octombrie, zi minunată de toamnă cu elevi frumoși dornici de lectură!Doamna profesor Radu Cătălina împreună cu un grup de elevi de la Colegiul Tehnic ,,Paul Dimo” au vizitat Filiala nr. 2 ,,Paul Păltănea” pentru a afla mai multe informații despre serviciile pe care biblioteca le oferă tuturor utilizatorilor.'
The answer should be:
{'entities': [(0, 20, 'DATETIME'), (37, 43, 'DATETIME'), (47, 52, 'PERSON'), (80, 109, 'PERSON'), (133, 138, 'PERSON'), (145, 173, 'ORG'), (185, 215, 'FACILITY'), (305, 319, 'PERSON')]})

Please generate the answer for this text:
'Joi, postul Al-Jazeera a difuzat apelul pe care liderul Consiliului Înțelepților Musulmani, Harith al Dhari, l-a făcut la răpitori pentru a-i elibera pe cei patru ostatici, spunând că o astfel de răpire aruncă Irakul și lumea arabă într-o lumină nefastă.'
